{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Machine Learning Project: Train Model to predict the author of a phrase\n",
        "#### Marc McAllister\n",
        "#### 2024\n",
        "\n",
        "###### Suggestions are welcome. Thank you."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow pandas scikit-learn\n",
        "!pip install tensorflow\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install nltk\n",
        "nltk.download('stopwords')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "CqkAWQVP3Lqq",
        "trusted": true,
        "gather": {
          "logged": 1721087988894
        },
        "editable": false,
        "run_control": {
          "frozen": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import seaborn as sns                       #visualisation\n",
        "import matplotlib.pyplot as plt             #visualisation\n",
        "import pickle\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "from nltk.corpus import stopwords"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-07-18 17:26:08.203851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-18 17:26:08.219441: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-18 17:26:08.219465: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-07-18 17:26:08.229333: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-07-18 17:26:09.020249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "ZA47UzCtsY9B",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:20:18.432246Z",
          "iopub.execute_input": "2024-01-27T16:20:18.432685Z",
          "iopub.status.idle": "2024-01-27T16:20:34.000604Z",
          "shell.execute_reply.started": "2024-01-27T16:20:18.432650Z",
          "shell.execute_reply": "2024-01-27T16:20:33.999374Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323569917
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folderpath = \"sources\"\n",
        "\n",
        "filenames = list()\n",
        "\n",
        "for name in os.listdir(folderpath):\n",
        "    if name.endswith('txt'):\n",
        "        filenames.append(name)\n",
        "        "
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721323570409
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and Process Data \n",
        "\n",
        "titles = []\n",
        "\n",
        "df = pd.DataFrame(columns=['Author','Text'])\n",
        "\n",
        "for fname in filenames:\n",
        "    samplefilepath = 'sources/' + fname\n",
        "    sampletext = pathlib.Path(samplefilepath).read_text()\n",
        "\n",
        "    title = sampletext.split('\\n')[0]\n",
        "    authorname = sampletext.split('\\n')[1]\n",
        "\n",
        "    sampletext = sampletext.replace(\"\\n\", \" \")\n",
        "    sampletext_sentences = sampletext.split(\".\")\n",
        "\n",
        "    titles.append(title)\n",
        "\n",
        "    i = len(sampletext_sentences)\n",
        "\n",
        "    data = {'Author': [authorname]*i,\n",
        "        'Text': sampletext_sentences}\n",
        "\n",
        "    dfsub = pd.DataFrame(data, columns=['Author','Text'])\n",
        "    #dfsub = dfsub[0:1000]      #For Small\n",
        "    df = pd.concat([df, dfsub])\n",
        "\n",
        "\n",
        "#df.to_csv('Text_Author.csv', index=False)\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721323570716
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start building Model\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['Text'], df['Author'], test_size=0.2, random_state=42)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "id": "wKtLCdqH1MfO",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:22:40.352415Z",
          "iopub.execute_input": "2024-01-27T16:22:40.353667Z",
          "iopub.status.idle": "2024-01-27T16:22:40.363053Z",
          "shell.execute_reply.started": "2024-01-27T16:22:40.353614Z",
          "shell.execute_reply": "2024-01-27T16:22:40.361920Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323571162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and vectorize text data\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "x_train = vectorizer.fit_transform(train_texts)\n",
        "x_test = vectorizer.transform(test_texts)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "id": "smx6lbID_cKz",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:22:43.981283Z",
          "iopub.execute_input": "2024-01-27T16:22:43.981911Z",
          "iopub.status.idle": "2024-01-27T16:22:44.456017Z",
          "shell.execute_reply.started": "2024-01-27T16:22:43.981880Z",
          "shell.execute_reply": "2024-01-27T16:22:44.454932Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323571998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_labels)\n",
        "y_test = label_encoder.transform(test_labels)\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "MBe37DLY_vJJ",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:22:47.319703Z",
          "iopub.execute_input": "2024-01-27T16:22:47.320149Z",
          "iopub.status.idle": "2024-01-27T16:22:47.329241Z",
          "shell.execute_reply.started": "2024-01-27T16:22:47.320117Z",
          "shell.execute_reply": "2024-01-27T16:22:47.328350Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323572868
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "GhCcMjW1A7Of",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:22:53.060811Z",
          "iopub.execute_input": "2024-01-27T16:22:53.061285Z",
          "iopub.status.idle": "2024-01-27T16:22:53.072771Z",
          "shell.execute_reply.started": "2024-01-27T16:22:53.061250Z",
          "shell.execute_reply": "2024-01-27T16:22:53.071607Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323574127
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sparse matrices\n",
        "\n",
        "x_train_sparse = tf.convert_to_tensor(csr_matrix(x_train).todense(), dtype=tf.float32)\n",
        "x_val_sparse = tf.convert_to_tensor(csr_matrix(x_val).todense(), dtype=tf.float32)\n",
        "x_test_sparse = tf.convert_to_tensor(csr_matrix(x_test).todense(), dtype=tf.float32)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-07-18 17:26:19.290337: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "id": "7kDXotUGBOUN",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:22:55.535092Z",
          "iopub.execute_input": "2024-01-27T16:22:55.535584Z",
          "iopub.status.idle": "2024-01-27T16:23:00.484501Z",
          "shell.execute_reply.started": "2024-01-27T16:22:55.535542Z",
          "shell.execute_reply": "2024-01-27T16:23:00.483522Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323580168
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "O6jNBPIJ_yqc",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:22:50.000518Z",
          "iopub.execute_input": "2024-01-27T16:22:50.000941Z",
          "iopub.status.idle": "2024-01-27T16:22:50.234616Z",
          "shell.execute_reply.started": "2024-01-27T16:22:50.000910Z",
          "shell.execute_reply": "2024-01-27T16:22:50.233640Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323580516
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "\n",
        "history = model.fit(x_train_sparse, y_train, epochs=10, batch_size=32, validation_data=(x_val_sparse, y_val))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5908 - loss: 1.0636 - val_accuracy: 0.7662 - val_loss: 0.6154\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.4511 - val_accuracy: 0.7743 - val_loss: 0.6099\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.3402 - val_accuracy: 0.7786 - val_loss: 0.6441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.2672 - val_accuracy: 0.7773 - val_loss: 0.6919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2321 - val_accuracy: 0.7694 - val_loss: 0.7553\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2037 - val_accuracy: 0.7781 - val_loss: 0.8322\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 0.1730 - val_accuracy: 0.7722 - val_loss: 0.9047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1461 - val_accuracy: 0.7637 - val_loss: 1.0065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1268 - val_accuracy: 0.7626 - val_loss: 1.0617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/10\n\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1120 - val_accuracy: 0.7671 - val_loss: 1.1665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iACWKVmA_3jh",
        "outputId": "6c8fdf86-81a2-4ecd-93db-33a9315aa2d9",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:23:03.050900Z",
          "iopub.execute_input": "2024-01-27T16:23:03.051317Z",
          "iopub.status.idle": "2024-01-27T16:24:19.053408Z",
          "shell.execute_reply.started": "2024-01-27T16:23:03.051286Z",
          "shell.execute_reply": "2024-01-27T16:24:19.052310Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323612645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "y_pred = predictions.argmax(axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTest Accuracy: 76.83%\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfCD_R8MAg_G",
        "outputId": "28558f0f-e92d-49bd-ec06-9eb4216f66e4",
        "execution": {
          "iopub.status.busy": "2024-01-27T16:27:22.053508Z",
          "iopub.execute_input": "2024-01-27T16:27:22.053981Z",
          "iopub.status.idle": "2024-01-27T16:27:22.530385Z",
          "shell.execute_reply.started": "2024-01-27T16:27:22.053944Z",
          "shell.execute_reply": "2024-01-27T16:27:22.529092Z"
        },
        "trusted": true,
        "gather": {
          "logged": 1721323613174
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "\n",
        "model.save('tensorflow_detection_model.keras')"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721323613419
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "\n",
        "test_text = 'ceaselessly into the past'\n",
        "\n",
        "print(test_text)\n",
        "\n",
        "tvector = vectorizer.transform([test_text])\n",
        "tsparse = tf.convert_to_tensor(tvector.todense(), dtype=tf.float32)\n",
        "pred = model.predict(tsparse)\n",
        "\n",
        "print(pred)\n",
        "print(np.argmax(pred))\n",
        "\n",
        "pred_label_index = np.argmax(pred)\n",
        "pred_label = label_encoder.classes_[pred_label_index]\n",
        "\n",
        "print(pred_label)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ceaselessly into the past\n\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n[[2.2101817e-03 9.4676441e-01 5.7903113e-04 5.1355992e-06 5.0441261e-02]]\n1\nF. Scott Fitzgerald\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721323613564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suggestions on accuracy?"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1929264,
          "sourceType": "datasetVersion",
          "datasetId": 1150837
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}